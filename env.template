# Solar Agent Configuration Template
# Copy this file to .env and update with your values

# =============================================================================
# Basic Application Settings
# =============================================================================
APP_NAME=Solar Agent
VERSION=1.0.0
DEBUG=false
LOG_LEVEL=INFO

# Server configuration
HOST=0.0.0.0
PORT=8000
RELOAD=false

# =============================================================================
# LLM Configuration - Choose your provider (openai, gemini, ollama)
# =============================================================================

# Primary LLM provider
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=1000
LLM_TIMEOUT=30

# Generic LLM settings (override provider-specific settings)
# LLM_API_KEY=your-api-key-here
# LLM_API_BASE=https://api.custom-provider.com

# -----------------------------------------------------------------------------
# OpenAI Configuration (Recommended for production)
# -----------------------------------------------------------------------------
# OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=1000

# For custom OpenAI endpoints (like Azure OpenAI)
# OPENAI_API_BASE=https://your-instance.openai.azure.com

# -----------------------------------------------------------------------------
# Google Gemini Configuration (Cost-effective cloud option)
# -----------------------------------------------------------------------------
# GEMINI_API_KEY=your-google-ai-api-key-here
GEMINI_MODEL=gemini-1.5-flash
GEMINI_TEMPERATURE=0.1
GEMINI_MAX_TOKENS=1000

# -----------------------------------------------------------------------------
# Ollama Configuration (Free local models)
# -----------------------------------------------------------------------------
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TEMPERATURE=0.1
OLLAMA_MAX_TOKENS=1000

# =============================================================================
# Hardware Adapter Settings
# =============================================================================
ADAPTER_TYPE=mock  # mock, sunspec
ADAPTER_HOST=localhost
ADAPTER_PORT=502
ADAPTER_UNIT_ID=1

# =============================================================================
# Agent Configuration
# =============================================================================
AGENT_ID=solar-agent-001
LOCATION=Default Location
CAPACITY_KW=5.0
EFFICIENCY=0.20

# =============================================================================
# Data Generation Settings (for mock adapter)
# =============================================================================
DATA_INTERVAL=5  # seconds between readings
ENABLE_FAULTS=true
FAULT_PROBABILITY=0.1  # 10% chance of faults
WEATHER_EFFECTS=true

# =============================================================================
# Database Settings
# =============================================================================
DATABASE_URL=sqlite:///./solar_agent.db

# For PostgreSQL (production)
# DATABASE_URL=postgresql://user:password@localhost:5432/solar_agent

# =============================================================================
# Security Settings
# =============================================================================
# API_KEY=your-secure-api-key-here
CORS_ORIGINS=*

# =============================================================================
# External Services
# =============================================================================
# MCP (Model Context Protocol) server for weather data
# MCP_SERVER_URL=http://localhost:8001

# Weather API for forecasting
# WEATHER_API_KEY=your-weather-api-key-here

# =============================================================================
# Example Provider Configurations
# =============================================================================

# Example 1: Using OpenAI GPT-4o-mini (Recommended)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# OPENAI_API_KEY=sk-your-openai-key

# Example 2: Using Gemini Flash (Cost-effective)
# LLM_PROVIDER=gemini
# LLM_MODEL=gemini-1.5-flash
# GEMINI_API_KEY=your-google-ai-key

# Example 3: Using Ollama with local Llama (Free & Private)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2
# OLLAMA_BASE_URL=http://localhost:11434

# Example 4: Using larger models for better accuracy
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o
# OPENAI_API_KEY=sk-your-openai-key
# LLM_MAX_TOKENS=2000

# Agent Identity
SOLAR_AGENT_ID=solar-001
SOLAR_CAPACITY_KW=100.0

# Server Configuration
SOLAR_HOST=0.0.0.0
SOLAR_PORT=8000
SOLAR_API_PREFIX=/api/v1

# Hardware Adapter Configuration
SOLAR_USE_MOCK_ADAPTER=true
SOLAR_SUNSPEC_HOST=192.168.1.100
SOLAR_SUNSPEC_PORT=502
SOLAR_SUNSPEC_UNIT_ID=1

# Workflow Configuration
SOLAR_WORKFLOW_INTERVAL_SECONDS=30
SOLAR_ENABLE_PERSISTENCE=true

# LLM Configuration (for forecasting)
OPENAI_API_KEY=your-openai-api-key-here
SOLAR_LLM_MODEL=gpt-3.5-turbo
SOLAR_LLM_TEMPERATURE=0.3

# External Services
SOLAR_UTILITY_AGENT_URL=http://utility-agent:8080
SOLAR_MCP_SERVER_URL=ws://weather-service:8765

# Logging Configuration
SOLAR_LOG_LEVEL=INFO
SOLAR_LOG_TO_FILE=true
SOLAR_ACCESS_LOG=true

# Security
SOLAR_ALLOWED_ORIGINS=["http://localhost:3000", "http://localhost:8080"]

# Redis (for caching and queuing)
REDIS_URL=redis://redis:6379/0

# Monitoring
PROMETHEUS_ENABLED=false
GRAFANA_ENABLED=false

# Development/Testing
SOLAR_ENABLE_MOCK_FAULTS=true
SOLAR_MOCK_FAULT_PROBABILITY=0.05
SOLAR_ENABLE_PERFORMANCE_MONITORING=true 